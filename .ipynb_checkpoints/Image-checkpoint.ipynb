{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad892551-51c6-4235-b566-474869fca4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('exoTrain.csv')  # Replace with actual train file path\n",
    "test_df = pd.read_csv('exoTest.csv')    # Replace with actual test file path\n",
    "\n",
    "flux_columns = [col for col in train_df.columns if 'flux' in col]\n",
    "\n",
    "X_train = train_df[flux_columns].values\n",
    "y_train = train_df['LABEL'].values  # Replace 'target' with label column\n",
    "\n",
    "X_test = test_df[flux_columns].values\n",
    "y_test = test_df['LABEL'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9d8d6a1-483e-4504-bc3f-57f47edf363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[flux_columns].values\n",
    "X_test = test_df[flux_columns].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cdd704f-d337-4213-9cc5-15407d012393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_train and y_test contain labels 1 and 2:\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5877b8f-596a-4be4-96f1-7cfdb68acea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape for CNN: (samples, channels=1, sequence_length)\n",
    "X_train_reshaped = X_train_scaled.reshape(-1, 1, X_train.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(-1, 1, X_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c293e21-8f2f-4252-9784-ba5ea9808d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class KeplerDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = KeplerDataset(X_train_reshaped, y_train)\n",
    "test_dataset = KeplerDataset(X_test_reshaped, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30aca1ae-c314-45d1-8dae-bbf46e8939db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: [5050 5050]\n",
      "Epoch 1/10, Loss: 1.3131\n",
      "Epoch 2/10, Loss: 0.5956\n",
      "Epoch 3/10, Loss: 0.5731\n",
      "Epoch 4/10, Loss: 0.4894\n",
      "Epoch 5/10, Loss: 0.3085\n",
      "Epoch 6/10, Loss: 0.2146\n",
      "Epoch 7/10, Loss: 0.1891\n",
      "Epoch 8/10, Loss: 0.1747\n",
      "Epoch 9/10, Loss: 0.2402\n",
      "Epoch 10/10, Loss: 0.1144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.98      0.99       565\n",
      "     Class 1       0.09      0.20      0.12         5\n",
      "\n",
      "    accuracy                           0.98       570\n",
      "   macro avg       0.54      0.59      0.56       570\n",
      "weighted avg       0.98      0.98      0.98       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Assuming you have these variables ready from your previous steps:\n",
    "# X_train: NumPy array of shape (num_train_samples, num_features)\n",
    "# y_train: NumPy array of labels (0 and 1)\n",
    "# X_test, y_test similarly for test set\n",
    "\n",
    "# 1. Apply SMOTE on training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Class distribution after SMOTE: {np.bincount(y_train_res)}\")\n",
    "\n",
    "# 2. Scale (normalize) data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Reshape for CNN input: (samples, channels=1, sequence_length)\n",
    "X_train_reshaped = X_train_scaled.reshape(-1, 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(-1, 1, X_test_scaled.shape[1])\n",
    "\n",
    "# 4. Dataset and DataLoader\n",
    "class KeplerDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = KeplerDataset(X_train_reshaped, y_train_res)\n",
    "test_dataset = KeplerDataset(X_test_reshaped, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 5. Define the 1D CNN model (from previous definition)\n",
    "class Kepler1DCNN(nn.Module):\n",
    "    def __init__(self, input_length, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(16, 32, 5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.conv3 = nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        pooled_length = input_length // 2\n",
    "        self.fc1 = nn.Linear(64 * pooled_length, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 6. Instantiate model\n",
    "input_length = X_train_reshaped.shape[2]\n",
    "model = Kepler1DCNN(input_length=input_length)\n",
    "\n",
    "# 7. Weighted Loss for balanced training\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_res), y=y_train_res)\n",
    "weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 8. Train\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 9. Evaluate\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=['Class 0', 'Class 1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635a5f3-90ee-4c72-8fc3-df8b0ffa079e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97dbc2-2571-4ed2-9024-171fc6766cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee97137e-2d6a-43b2-ab7a-7f95f49e8644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40819316-8838-4a7f-a478-a6e38664c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09c79096-a378-48e2-8510-d30f46c6024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.98      0.99       565\n",
      "     Class 1       0.09      0.20      0.12         5\n",
      "\n",
      "    accuracy                           0.98       570\n",
      "   macro avg       0.54      0.59      0.56       570\n",
      "weighted avg       0.98      0.98      0.98       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# all_labels and all_preds from prediction step\n",
    "print(classification_report(all_labels, all_preds, target_names=['Class 0', 'Class 1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74992b67-875b-44f4-8e82-cde945cda74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
